{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from __future__ import division\n",
    "from sklearn import cross_validation\n",
    "digits = load_digits()\n",
    "data = digits [ \"data\" ]\n",
    "images = digits [ \"images\" ]\n",
    "target = digits [ \"target\" ]\n",
    "target_names = digits [ \"target_names\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subtract mean vector and divide each feature vector by the standard deviation of the whole dataset\n",
    "X = (data - np.mean(data,axis=0))\n",
    "X = X/np.std(X)\n",
    "\n",
    "# X^k\n",
    "X_0 = X[np.where(target==0)]\n",
    "X_1 = X[np.where(target==1)]\n",
    "X_2 = X[np.where(target==2)]\n",
    "X_3 = X[np.where(target==3)]\n",
    "X_4 = X[np.where(target==4)]\n",
    "X_5 = X[np.where(target==5)]\n",
    "X_6 = X[np.where(target==6)]\n",
    "X_7 = X[np.where(target==7)]\n",
    "X_8 = X[np.where(target==8)]\n",
    "X_9 = X[np.where(target==9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select a test and training set\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, target,\n",
    "                                            random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class one_vs_rest:\n",
    "    def __init__(self, X,Y, binary=True, subsampling=True):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.binary = binary\n",
    "        if subsampling:\n",
    "            self.subsampling = \"balanced_subsample\"  # may be \"subsample\" or \"balanced_subsample\", depending on version of sklearn\n",
    "        else:\n",
    "            self.subsampling = \"auto\"\n",
    "    \n",
    "    def train(self):\n",
    "        self.clfs = []\n",
    "        for i in range(0,10):\n",
    "            y = np.zeros(self.Y.size)\n",
    "            y[np.where(self.Y == i)] = 1 \n",
    "            rfc = RandomForestClassifier(n_estimators = 10, class_weight = self.subsampling)\n",
    "            rfc.fit(self.X,y)\n",
    "            self.clfs.append(rfc)\n",
    "            \n",
    "    def predict(self, test):  \n",
    "        pred = []\n",
    "        \n",
    "        if self.binary:\n",
    "            for i in range(0,10):\n",
    "                pred.append(self.clfs[i].predict(test))\n",
    "            return np.array(pred)\n",
    "        else:\n",
    "            for i in range(0,10):\n",
    "                pred.append(self.clfs[i].predict_proba(test))\n",
    "            return np.argmax(np.array(pred),axis=0)\n",
    "        \n",
    "    def tot_error(self, test_x, test_y):\n",
    "            pred = self.predict(test_x)\n",
    "            if self.binary:\n",
    "                y = np.zeros(pred.shape)\n",
    "                for num, i in enumerate(test_y):\n",
    "                    y[i,num]=1\n",
    "                return np.sum(np.not_equal(pred,y))/len(test_x)\n",
    "                \n",
    "            else:\n",
    "                pred = pred[:,1]\n",
    "                return np.sum(np.not_equal(pred,test_y))/len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048148148148148148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without weighted loss, argmax\n",
    "ovr = one_vs_rest(X_train,y_train, 0,0)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05185185185185185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With subsampling, argmax\n",
    "ovr = one_vs_rest(X_train,y_train, 0,1)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22222222222222221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without weighted loss, binary\n",
    "ovr = one_vs_rest(X_train,y_train, 1,0)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22592592592592592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsampling, binary\n",
    "ovr = one_vs_rest(X_train,y_train, 1,1)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the methods seems to profit significantly from the weighted loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 One - vs - One Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class one_vs_one:\n",
    "    def __init__(self, X,Y, subsampling=True, method=1):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.method = method\n",
    "        if subsampling:\n",
    "            self.subsampling = \"balanced_subsample\" # may be \"subsample\" or \"balanced_subsample\", depending on version of sklearn\n",
    "        else:\n",
    "            self.subsampling = \"auto\"\n",
    "    \n",
    "    def train(self):\n",
    "        self.clfs = []\n",
    "        if self.method == 1:\n",
    "            for i in range(0,10):\n",
    "                for j in range(i+1,10):\n",
    "                    X_classes = self.X[(self.Y==i)|(self.Y==j)]\n",
    "                    y = self.Y[(self.Y==i)|(self.Y==j)]\n",
    "                    y[y == i] = 1\n",
    "                    y[y == j] = 0\n",
    "                    rfc = RandomForestClassifier(n_estimators = 10, class_weight = self.subsampling)\n",
    "                    rfc.fit(X_classes,y)\n",
    "                    self.clfs.append(rfc)\n",
    "        else:\n",
    "            for i in range(0,9):\n",
    "                X_classes = self.X[(self.Y==i)|(self.Y==i+1)]\n",
    "                y = self.Y[(self.Y==i)|(self.Y==i+1)]\n",
    "                y[y == i] = 0\n",
    "                y[y == i+1] = 1\n",
    "                rfc = RandomForestClassifier(n_estimators = 10, class_weight = self.subsampling)\n",
    "                rfc.fit(X_classes,y)\n",
    "                self.clfs.append(rfc)\n",
    "     \n",
    "            \n",
    "    def predict(self, test):  \n",
    "        if self.method == 1:\n",
    "            preds = np.zeros((np.shape(test)[0],10))\n",
    "            k = 0\n",
    "            for i in range(0,10):\n",
    "                for j in range(i+1,10):\n",
    "                    pred=(self.clfs[k].predict(test))\n",
    "                    preds[:,i] = preds[:,i]+pred\n",
    "                    preds[:,j] = preds[:,j]-(pred-1)\n",
    "                    k = k+1\n",
    "            return np.argmax(preds,axis = 1)\n",
    "        else:\n",
    "            pred = np.zeros((np.shape(test)[0]))\n",
    "            for i in range(0,np.shape(test)[0]):\n",
    "                a = 0\n",
    "                b = 10\n",
    "                while (a != b-1):\n",
    "                    a_prob = self.clfs[a].predict_proba(test[i:i+1,:])[0,0]\n",
    "                    b_prob =  self.clfs[b-2].predict_proba(test[i:i+1,:])[0,0]\n",
    "                    if a_prob>(1-b_prob):\n",
    "                        b = b-1\n",
    "                    else:\n",
    "                        a = a+1\n",
    "                pred[i] = a\n",
    "            return pred\n",
    "        \n",
    "    def tot_error(self, test_x, test_y):\n",
    "            pred = self.predict(test_x)\n",
    "            return np.sum(np.not_equal(pred,test_y))/len(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062962962962962957"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr = one_vs_one(X_train,y_train, 1,1)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24259259259259258"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr = one_vs_one(X_train,y_train, 1,2)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# 1.5 Multi-Class Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class multiclass:\n",
    "    def __init__(self, X,Y, subsampling=True,binary = True):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.binary = binary\n",
    "        if subsampling:\n",
    "            self.subsampling = \"balanced_subsample\" # may be \"subsample\" or \"balanced_subsample\", depending on version of sklearn\n",
    "        else:\n",
    "            self.subsampling = \"auto\"\n",
    "    \n",
    "    def train(self):\n",
    "        rfc = RandomForestClassifier(n_estimators = 100, class_weight = self.subsampling)\n",
    "        self.clfs = rfc.fit(self.X,self.Y)\n",
    "     \n",
    "    def predict(self, test):  \n",
    "        if self.binary:\n",
    "            return np.array(self.clfs.predict(test))\n",
    "        else:\n",
    "            return np.argmax(self.clfs.predict_proba(test),axis = 1)\n",
    "\n",
    "        \n",
    "    def tot_error(self, test_x, test_y):\n",
    "            pred = self.predict(test_x)\n",
    "            return np.sum(np.not_equal(pred,test_y))/len(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0296296296296\n"
     ]
    }
   ],
   "source": [
    "# Without weighted loss, binary\n",
    "ovr = multiclass(X_train,y_train, 0,1)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0277777777778\n"
     ]
    }
   ],
   "source": [
    "# Without weighted loss, argmax\n",
    "ovr = multiclass(X_train,y_train, 0,0)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0277777777778\n"
     ]
    }
   ],
   "source": [
    "# With subsampling, binary\n",
    "ovr = multiclass(X_train,y_train, 1,1)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0185185185185\n"
     ]
    }
   ],
   "source": [
    "# With subsampling, argmax\n",
    "ovr = multiclass(X_train,y_train, 1,0)\n",
    "ovr.train()\n",
    "err = ovr.tot_error(X_test,y_test)\n",
    "print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
